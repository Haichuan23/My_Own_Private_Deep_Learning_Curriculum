# Section 1: AI Safety Glossary

Model Spec: Document that outlines intended behaviors of a model, often following a hierarchical structure, e.g., root > system > developer > user </br>
Website: https://model-spec.openai.com/2025-09-12.html

Sandbagging: Strategic underperformance on an evaluation </br>
Website: https://www.lesswrong.com/posts/jsmNCj9QKcfdg8fJk/an-introduction-to-ai-sandbagging

Scheming: AI pretends to be aligned while secretly pursuing some other agenda.</br>
Website: https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/

Sycophancy: AI amodels align their responses with a user's beliefs or opinions, even when the information is incorrect, to appear favorable. </br>
Website: https://www.nngroup.com/articles/sycophancy-generative-ai-chatbots/

